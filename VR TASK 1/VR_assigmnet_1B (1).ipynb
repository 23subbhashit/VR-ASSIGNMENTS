{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Image 1"
      ],
      "metadata": {
        "id": "tWBV_Wl93kV2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XptV5ALf2uRy"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def improve_image_contrast(input_image_path, clip_limit=3.0, tile_grid_size=(8, 8)):\n",
        "\n",
        "    input_image = cv2.imread(input_image_path)\n",
        "\n",
        "    # Convert the image to LAB color space\n",
        "    lab_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2LAB)\n",
        "\n",
        "    # Extract the L channel (luminance) from LAB\n",
        "    luminance_channel = lab_image[:, :, 0]\n",
        "\n",
        "    # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization) to the L channel\n",
        "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
        "    enhanced_luminance_channel = clahe.apply(luminance_channel)\n",
        "\n",
        "    # Replace the original L channel with the enhanced one\n",
        "    lab_image[:, :, 0] = enhanced_luminance_channel\n",
        "\n",
        "    # Convert the enhanced LAB image back to BGR\n",
        "    enhanced_image = cv2.cvtColor(lab_image, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "\n",
        "    cv2_imshow(input_image)\n",
        "    cv2_imshow(enhanced_image)\n",
        "\n",
        "    return enhanced_image\n",
        "input_image_path = '/content/ShadowRemoval1.jpg'\n",
        "improved_contrast_image = improve_image_contrast(input_image_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "from tqdm import tqdm\n",
        "\n",
        "def process_shadow_reduction(input_image, luminance_thresholds=((0, 15), (45, 65)), neighborhood_size=1000):\n",
        "    # Convert the input image from BGR to LAB color space\n",
        "    lab_image_input = cv2.cvtColor(input_image, cv2.COLOR_BGR2LAB)\n",
        "\n",
        "    # Extract the luminance channel (L) from LAB\n",
        "    luminance_channel_input = lab_image_input[:, :, 0]\n",
        "\n",
        "    # Create a binary mask for shadow regions based on luminance thresholds\n",
        "    shadow_mask_input = np.zeros_like(luminance_channel_input, dtype=np.uint8)\n",
        "    for lower, upper in luminance_thresholds:\n",
        "        shadow_mask_input |= ((luminance_channel_input > lower) & (luminance_channel_input < upper)).astype(np.uint8) * 255\n",
        "\n",
        "    # Invert the shadow mask to obtain the non-shadow regions\n",
        "    non_shadow_mask_input = cv2.bitwise_not(shadow_mask_input)\n",
        "\n",
        "    # Extract the neighborhood around each non-shadow pixel\n",
        "    neighborhood_input = cv2.boxFilter(lab_image_input, -1, (neighborhood_size, neighborhood_size))\n",
        "\n",
        "    # Calculate the average luminance of the neighborhood for each non-shadow pixel\n",
        "    average_luminance_input = neighborhood_input / cv2.boxFilter(np.ones_like(lab_image_input), -1, (neighborhood_size, neighborhood_size))\n",
        "\n",
        "    # Replace the shadow regions with the calculated average luminance\n",
        "    result_image_lab = np.where(shadow_mask_input[..., None], average_luminance_input, lab_image_input)\n",
        "\n",
        "    # Convert the result image back to BGR\n",
        "    result_image_bgr = cv2.cvtColor(result_image_lab.astype(np.uint8), cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    cv2_imshow(input_image)\n",
        "    cv2_imshow(shadow_mask_input)\n",
        "    cv2_imshow(result_image_bgr)\n",
        "\n",
        "# UNCOMMENT THIS TO RUN IT\n",
        "# COMMENTED IT AS IT WAS TAKING EXTRA SPACE, AND ZIP FILE SIZE BECAME MORE THAN 20MB. So i commented the fucntion call here\n",
        "# To run this, just uncomment it , upload the image and run this cell\n",
        "#process_shadow_reduction(improved_contrast_image, luminance_thresholds=((0, 1), (35, 75)), neighborhood_size=500)"
      ],
      "metadata": {
        "id": "fj2F3OO33HpO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image 2"
      ],
      "metadata": {
        "id": "8OqqvKTI7k0u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# input_image_path = '/content/ShadowRemoval1.jpg'\n",
        "# input_image = cv2.imread(input_image_path)\n",
        "# process_shadow_reduction(improved_contrast_image, luminance_thresholds=((0, 9), (55, 150)), neighborhood_size=500)\n",
        "\n",
        "# Was taking space so commented . If you want to run it, just uncomment it"
      ],
      "metadata": {
        "id": "e5a7v_gT7j2X"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o08sBJut7-DW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}